一. bert模型

原理：

基于预训练 BERT 的上下文语义编码，通过全连接层输出类别概率，属于 “语义理解型”

优点：
1. 捕捉上下文语义（如歧义句、倒装句），分类准确率最高；
2. 对低频次 / 小众类别覆盖性好；
3. 抗文本噪声（错别字 / 口语化）能力强
4. 批处理（batch_size=16）提升大批量推理效率；


缺点：
1. 开发 / 调参成本高（需调 batch_size / 学习率 /epochs）；
2. 部署依赖 GPU / 大内存服务器；
3. 版本兼容风险（transformers 版本变化）
4. 对输入长度敏感（max_length=30），超长文本截断后出错；
5. 模型权重文件损坏则无法推理
6. 依赖高质量标注数据，数据不足时精度骤降；
7. 对超长文本（截断后）可能丢失关键信息


二. TF-IDF

原理：基于词频 - 逆文档频率的文本特征量化，结合传统机器学习模型（如 SVM / 逻辑回归）分类，属于 “词袋特征型”

优点：

1. 精度优于正则，能处理简单语义差异；
2. 推理速度极快,内存占用极低
3. 训练后效果稳定，无随机误差
4. 开发 / 调试成本低,部署简单

缺点：

1. 无语义理解能力，无法处理歧义 / 多义词；
2. 对长文本 / 低频次词敏感；
3. 依赖分词效果
4. 泛化性差，未见过的词汇 / 句式分类错误，停用词表更新不及时影响精度

三. LLM

原理：基于大模型的自然语言理解 + 动态相似样本提示，通过 Prompt 引导分类，属于 “指令遵循型”

优点：

1. 零 / 少样本场景下精度远超 TF-IDF / 正则，甚至接近 BERT；
2. 动态相似样本提示进一步提升精度；
3. 能理解复杂句式 / 隐含意图
4. 无版本兼容问题
5. 无需训练 / 调参，开发成本最低；
6. 新增类别仅需修改提示词，无需改代码

缺点：

1. 存在 “幻觉”（输出非待选类别）；
2. 对提示词格式敏感，格式变化可能导致分类错误；
3. 相似样本质量差时精度下降
4. 不同大模型效果差异大，指令遵循性不稳定

四. 正则

原理：基于关键词 / 句式的正则匹配规则，命中则归类，属于 “规则匹配型”

优点：

1. 规则明确，命中的样本分类 100% 符合预期；
2. 对高频核心关键词的文本分类无误差
3. 速度最快
4. 几乎无内存占用
5. 并发能力无上限
6. 开发成本极低

缺点：

1. 无法处理隐含意图
2. 规则覆盖不全，大量样本归为 Other
3. 新增类别需手动加规则
4. 大批量推理时，多规则遍历会增加少量耗时
5. 规则数量过多时匹配效率下降
6. 规则维护成本高，规则冲突需要手动解决，无泛化能力，规则需持续迭代